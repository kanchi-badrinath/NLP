YOUTUBE LINK :
https://www.youtube.com/watch?v=lC2ozyRvlhA 

Automated title generation for academic papers using natural language processing (NLP) techniques garnered significant attention for its potential to enhance research productivity and information retrieval systems. In this report, we explored the utilization of Long Short-Term Memory (LSTM) and feedforward neural network models for generating titles based on the content of academic papers. The project involved discussing preprocessing steps, model architectures, evaluation metrics, methodology, results, inference, future scope, and conclusion.Two primary model architectures were employed: LSTM and feedforward neural networks. LSTM models were chosen for their ability to process sequential data, making them suitable for generating titles based on the sequential nature of language. Feedforward neural network models, on the other hand, offered simplicity and efficiency in training, making them a viable alternative for title generation tasks.To evaluate the performance of the models, several evaluation metrics commonly used in NLP tasks were employed, including accuracy, precision, recall, and F1-score. These metrics provided quantitative measures of the quality and relevance of the generated titles compared to human-generated or ground truth titles from the dataset.The methodology involved training the LSTM and feedforward neural network models on preprocessed datasets and evaluating their performance using the aforementioned evaluation metrics. The datasets were split into training and testing sets to assess the generalization ability of the models. The models were trained using gradient descent optimization techniques, with hyperparameters tuned through experimentation.The results indicated that the LSTM model achieved a test accuracy of 99.90%, while the feedforward neural network model achieved a test accuracy of 97.78%. Additionally, the LSTM model outperformed the feedforward neural network model in terms of accuracy, precision, recall, and F1-score. Inference from the results suggested that the LSTM model was more effective in generating accurate and relevant titles for academic papers compared to the feedforward neural network model.
